<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Schema DDL operations | JSON Exchange</title>
<meta name="generator" content="Jekyll v3.8.3" />
<meta property="og:title" content="Schema DDL operations" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Adding DDL operations in the export file. The previous post described a package for importing data from the files generated by JSON_EXPORT. It also described a method for testing this package which relied on using Oracle’s classing export (exp) and import(imp) utilities to create an empty clone of a database schema. The method works for the HR schema, Unfortunately when it applied to the other sample schemas, a number of errors are reported during the import operation, including illegal identifiers and unsupported data types. Clearly another solution to duplicating a schema’s structure is required. This post introduces the PL/SQL package JSON_EXPORT_DDL. This package provides two functions. The first, FETCH_DDL_STATEMENTS, returns the set of DDL statements used to create all of the objects in the schema. The second, APPLY_DDL_STATEMENTS replays the DDL captured by FETCH_DLL_STATEMENTS in the target schema, effective turning the target schema into a structural clone of the source schema. The FETCH_DDL_STATEMENTS function uses the Oracle supplied package DBMS_METADATA to obtain the set of DLL operations used to create the source schema. The order in which DDL Operations are exported is as follows XML Schemas, generated using DBMS_METADATA. XML Schemas must be registered in the target schema before attempting to perform DDL operations. DLL Operations, generated using DBMS_METADATA. DBMS_METADATA is configured to omit storage clauses making it much easier to replay the DLL operations in the target environment. DMS_XDBZ.enableHierarchy() operations. This re-establishes any relationship between an XMLType table and the XML DB repository. Index naming operations. This ensure that system generated index names from the source schema are preserved in the target schema. The code used to access the DDL operations is shown below begin V_HDL_OPEN := DBMS_METADATA.OPEN(&#39;SCHEMA_EXPORT&#39;); DBMS_METADATA.SET_FILTER(V_HDL_OPEN,&#39;SCHEMA&#39;,P_SCHEMA); V_HDL_TRANSFORM := DBMS_METADATA.ADD_TRANSFORM(V_HDL_OPEN,&#39;DDL&#39;); -- Suppress Segement information for TABLES, INDEXES and CONSTRAINTS DBMS_METADATA.SET_TRANSFORM_PARAM(V_HDL_TRANSFORM,&#39;SEGMENT_ATTRIBUTES&#39;,false,&#39;TABLE&#39;); DBMS_METADATA.SET_TRANSFORM_PARAM(V_HDL_TRANSFORM,&#39;SEGMENT_ATTRIBUTES&#39;,false,&#39;INDEX&#39;); DBMS_METADATA.SET_TRANSFORM_PARAM(V_HDL_TRANSFORM,&#39;SEGMENT_ATTRIBUTES&#39;,false,&#39;CONSTRAINT&#39;); -- Return constraints as &#39;ALTER TABLE&#39; operations DBMS_METADATA.SET_TRANSFORM_PARAM(V_HDL_TRANSFORM,&#39;CONSTRAINTS_AS_ALTER&#39;,true,&#39;TABLE&#39;); DBMS_METADATA.SET_TRANSFORM_PARAM(V_HDL_TRANSFORM,&#39;REF_CONSTRAINTS&#39;,false,&#39;TABLE&#39;); -- Exclude XML Schema Info. XML Schemas need to come first and -- are handled in a seperate section DBMS_METADATA.SET_FILTER(V_HDL_OPEN,&#39;EXCLUDE_PATH_EXPR&#39;,&#39;=&#39;&#39;XMLSCHEMA&#39;&#39;&#39;); loop -- Get the next batch of DDL_STATEMENTS. Each batch may contain zero or more statements. V_DDL_STATEMENTS := DBMS_METADATA.FETCH_DDL(V_HDL_OPEN); EXIT WHEN V_DDL_STATEMENTS IS NULL; for i in 1 .. V_DDL_STATEMENTS.count loop V_DDL_STATEMENT := V_DDL_STATEMENTS(i).DDLTEXT; -- Strip leading and trailing white space from DDL statement V_DDL_STATEMENT := TRIM(BOTH C_NEWLINE FROM V_DDL_STATEMENT); V_DDL_STATEMENT := TRIM(BOTH C_CARRIAGE_RETURN FROM V_DDL_STATEMENT); V_DDL_STATEMENT := TRIM(V_DDL_STATEMENT); PIPE ROW (TRIM(V_DDL_STATEMENT)); end loop; end loop; The EXPORT_SCHEMA function inserts a “ddl” object into the export file immediately after the “systemInformation” object. The “ddl” object is created based on the DDL statements returned by FETCH_DLL_STATEMENTS. The “ddl” object is an array, each item in the array contains a single ddl operation. The IMPORT_JSON function passes the export file to APPLY_DDL_STATEMENTS before attempting to import data. This function uses JSON_TABLE to extract each of the ddl statements from the dump and executes them in order.Before replaying a DDL operation all references to the source schema are replaced with references to the target schema. This enables cloning from schema A to schema B. Exceptions may be raised while replaying the DDL generated by DBMS_METADATA. In most cases these can be safely ignored. Duplicate name/key/index/constraint exceptions occur because the DDL generated by DBMS_METADATA results in some objects being created more than once. Exceptions also arise when re-creating constraints if the required permissions have not been granted to the target schema . Exceptions are raised if the source schema uses Oracle Advanced Queuing (AQ). When AQ is present in the source DBMS_METADATA generates operations that cannot be replayed in the target schemas, even by a DBA. Any exceptions that arise while replaying the DDL statements are caught, classified as IGNOREABLE, DUPLICATE, REFERENCE WARNING, AQ_RELATED, or FATAL and logged. The log of DDL operations can be queried by applying a table operator to the IMPORT_DDL_LOG function. EXPORT_SCHEMA and IMPORT_JSON are now theoretically capable of cloning any database schema. The next post will examine what occurs when attempting to clone each of the six Oracle supplied sample schemas." />
<meta property="og:description" content="Adding DDL operations in the export file. The previous post described a package for importing data from the files generated by JSON_EXPORT. It also described a method for testing this package which relied on using Oracle’s classing export (exp) and import(imp) utilities to create an empty clone of a database schema. The method works for the HR schema, Unfortunately when it applied to the other sample schemas, a number of errors are reported during the import operation, including illegal identifiers and unsupported data types. Clearly another solution to duplicating a schema’s structure is required. This post introduces the PL/SQL package JSON_EXPORT_DDL. This package provides two functions. The first, FETCH_DDL_STATEMENTS, returns the set of DDL statements used to create all of the objects in the schema. The second, APPLY_DDL_STATEMENTS replays the DDL captured by FETCH_DLL_STATEMENTS in the target schema, effective turning the target schema into a structural clone of the source schema. The FETCH_DDL_STATEMENTS function uses the Oracle supplied package DBMS_METADATA to obtain the set of DLL operations used to create the source schema. The order in which DDL Operations are exported is as follows XML Schemas, generated using DBMS_METADATA. XML Schemas must be registered in the target schema before attempting to perform DDL operations. DLL Operations, generated using DBMS_METADATA. DBMS_METADATA is configured to omit storage clauses making it much easier to replay the DLL operations in the target environment. DMS_XDBZ.enableHierarchy() operations. This re-establishes any relationship between an XMLType table and the XML DB repository. Index naming operations. This ensure that system generated index names from the source schema are preserved in the target schema. The code used to access the DDL operations is shown below begin V_HDL_OPEN := DBMS_METADATA.OPEN(&#39;SCHEMA_EXPORT&#39;); DBMS_METADATA.SET_FILTER(V_HDL_OPEN,&#39;SCHEMA&#39;,P_SCHEMA); V_HDL_TRANSFORM := DBMS_METADATA.ADD_TRANSFORM(V_HDL_OPEN,&#39;DDL&#39;); -- Suppress Segement information for TABLES, INDEXES and CONSTRAINTS DBMS_METADATA.SET_TRANSFORM_PARAM(V_HDL_TRANSFORM,&#39;SEGMENT_ATTRIBUTES&#39;,false,&#39;TABLE&#39;); DBMS_METADATA.SET_TRANSFORM_PARAM(V_HDL_TRANSFORM,&#39;SEGMENT_ATTRIBUTES&#39;,false,&#39;INDEX&#39;); DBMS_METADATA.SET_TRANSFORM_PARAM(V_HDL_TRANSFORM,&#39;SEGMENT_ATTRIBUTES&#39;,false,&#39;CONSTRAINT&#39;); -- Return constraints as &#39;ALTER TABLE&#39; operations DBMS_METADATA.SET_TRANSFORM_PARAM(V_HDL_TRANSFORM,&#39;CONSTRAINTS_AS_ALTER&#39;,true,&#39;TABLE&#39;); DBMS_METADATA.SET_TRANSFORM_PARAM(V_HDL_TRANSFORM,&#39;REF_CONSTRAINTS&#39;,false,&#39;TABLE&#39;); -- Exclude XML Schema Info. XML Schemas need to come first and -- are handled in a seperate section DBMS_METADATA.SET_FILTER(V_HDL_OPEN,&#39;EXCLUDE_PATH_EXPR&#39;,&#39;=&#39;&#39;XMLSCHEMA&#39;&#39;&#39;); loop -- Get the next batch of DDL_STATEMENTS. Each batch may contain zero or more statements. V_DDL_STATEMENTS := DBMS_METADATA.FETCH_DDL(V_HDL_OPEN); EXIT WHEN V_DDL_STATEMENTS IS NULL; for i in 1 .. V_DDL_STATEMENTS.count loop V_DDL_STATEMENT := V_DDL_STATEMENTS(i).DDLTEXT; -- Strip leading and trailing white space from DDL statement V_DDL_STATEMENT := TRIM(BOTH C_NEWLINE FROM V_DDL_STATEMENT); V_DDL_STATEMENT := TRIM(BOTH C_CARRIAGE_RETURN FROM V_DDL_STATEMENT); V_DDL_STATEMENT := TRIM(V_DDL_STATEMENT); PIPE ROW (TRIM(V_DDL_STATEMENT)); end loop; end loop; The EXPORT_SCHEMA function inserts a “ddl” object into the export file immediately after the “systemInformation” object. The “ddl” object is created based on the DDL statements returned by FETCH_DLL_STATEMENTS. The “ddl” object is an array, each item in the array contains a single ddl operation. The IMPORT_JSON function passes the export file to APPLY_DDL_STATEMENTS before attempting to import data. This function uses JSON_TABLE to extract each of the ddl statements from the dump and executes them in order.Before replaying a DDL operation all references to the source schema are replaced with references to the target schema. This enables cloning from schema A to schema B. Exceptions may be raised while replaying the DDL generated by DBMS_METADATA. In most cases these can be safely ignored. Duplicate name/key/index/constraint exceptions occur because the DDL generated by DBMS_METADATA results in some objects being created more than once. Exceptions also arise when re-creating constraints if the required permissions have not been granted to the target schema . Exceptions are raised if the source schema uses Oracle Advanced Queuing (AQ). When AQ is present in the source DBMS_METADATA generates operations that cannot be replayed in the target schemas, even by a DBA. Any exceptions that arise while replaying the DDL statements are caught, classified as IGNOREABLE, DUPLICATE, REFERENCE WARNING, AQ_RELATED, or FATAL and logged. The log of DDL operations can be queried by applying a table operator to the IMPORT_DDL_LOG function. EXPORT_SCHEMA and IMPORT_JSON are now theoretically capable of cloning any database schema. The next post will examine what occurs when attempting to clone each of the six Oracle supplied sample schemas." />
<link rel="canonical" href="http://localhost:4000/json/import/export/oracle/2018/06/21/DDL-Operations.html" />
<meta property="og:url" content="http://localhost:4000/json/import/export/oracle/2018/06/21/DDL-Operations.html" />
<meta property="og:site_name" content="JSON Exchange" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2018-06-21T18:00:00-07:00" />
<script type="application/ld+json">
{"description":"Adding DDL operations in the export file. The previous post described a package for importing data from the files generated by JSON_EXPORT. It also described a method for testing this package which relied on using Oracle’s classing export (exp) and import(imp) utilities to create an empty clone of a database schema. The method works for the HR schema, Unfortunately when it applied to the other sample schemas, a number of errors are reported during the import operation, including illegal identifiers and unsupported data types. Clearly another solution to duplicating a schema’s structure is required. This post introduces the PL/SQL package JSON_EXPORT_DDL. This package provides two functions. The first, FETCH_DDL_STATEMENTS, returns the set of DDL statements used to create all of the objects in the schema. The second, APPLY_DDL_STATEMENTS replays the DDL captured by FETCH_DLL_STATEMENTS in the target schema, effective turning the target schema into a structural clone of the source schema. The FETCH_DDL_STATEMENTS function uses the Oracle supplied package DBMS_METADATA to obtain the set of DLL operations used to create the source schema. The order in which DDL Operations are exported is as follows XML Schemas, generated using DBMS_METADATA. XML Schemas must be registered in the target schema before attempting to perform DDL operations. DLL Operations, generated using DBMS_METADATA. DBMS_METADATA is configured to omit storage clauses making it much easier to replay the DLL operations in the target environment. DMS_XDBZ.enableHierarchy() operations. This re-establishes any relationship between an XMLType table and the XML DB repository. Index naming operations. This ensure that system generated index names from the source schema are preserved in the target schema. The code used to access the DDL operations is shown below begin V_HDL_OPEN := DBMS_METADATA.OPEN(&#39;SCHEMA_EXPORT&#39;); DBMS_METADATA.SET_FILTER(V_HDL_OPEN,&#39;SCHEMA&#39;,P_SCHEMA); V_HDL_TRANSFORM := DBMS_METADATA.ADD_TRANSFORM(V_HDL_OPEN,&#39;DDL&#39;); -- Suppress Segement information for TABLES, INDEXES and CONSTRAINTS DBMS_METADATA.SET_TRANSFORM_PARAM(V_HDL_TRANSFORM,&#39;SEGMENT_ATTRIBUTES&#39;,false,&#39;TABLE&#39;); DBMS_METADATA.SET_TRANSFORM_PARAM(V_HDL_TRANSFORM,&#39;SEGMENT_ATTRIBUTES&#39;,false,&#39;INDEX&#39;); DBMS_METADATA.SET_TRANSFORM_PARAM(V_HDL_TRANSFORM,&#39;SEGMENT_ATTRIBUTES&#39;,false,&#39;CONSTRAINT&#39;); -- Return constraints as &#39;ALTER TABLE&#39; operations DBMS_METADATA.SET_TRANSFORM_PARAM(V_HDL_TRANSFORM,&#39;CONSTRAINTS_AS_ALTER&#39;,true,&#39;TABLE&#39;); DBMS_METADATA.SET_TRANSFORM_PARAM(V_HDL_TRANSFORM,&#39;REF_CONSTRAINTS&#39;,false,&#39;TABLE&#39;); -- Exclude XML Schema Info. XML Schemas need to come first and -- are handled in a seperate section DBMS_METADATA.SET_FILTER(V_HDL_OPEN,&#39;EXCLUDE_PATH_EXPR&#39;,&#39;=&#39;&#39;XMLSCHEMA&#39;&#39;&#39;); loop -- Get the next batch of DDL_STATEMENTS. Each batch may contain zero or more statements. V_DDL_STATEMENTS := DBMS_METADATA.FETCH_DDL(V_HDL_OPEN); EXIT WHEN V_DDL_STATEMENTS IS NULL; for i in 1 .. V_DDL_STATEMENTS.count loop V_DDL_STATEMENT := V_DDL_STATEMENTS(i).DDLTEXT; -- Strip leading and trailing white space from DDL statement V_DDL_STATEMENT := TRIM(BOTH C_NEWLINE FROM V_DDL_STATEMENT); V_DDL_STATEMENT := TRIM(BOTH C_CARRIAGE_RETURN FROM V_DDL_STATEMENT); V_DDL_STATEMENT := TRIM(V_DDL_STATEMENT); PIPE ROW (TRIM(V_DDL_STATEMENT)); end loop; end loop; The EXPORT_SCHEMA function inserts a “ddl” object into the export file immediately after the “systemInformation” object. The “ddl” object is created based on the DDL statements returned by FETCH_DLL_STATEMENTS. The “ddl” object is an array, each item in the array contains a single ddl operation. The IMPORT_JSON function passes the export file to APPLY_DDL_STATEMENTS before attempting to import data. This function uses JSON_TABLE to extract each of the ddl statements from the dump and executes them in order.Before replaying a DDL operation all references to the source schema are replaced with references to the target schema. This enables cloning from schema A to schema B. Exceptions may be raised while replaying the DDL generated by DBMS_METADATA. In most cases these can be safely ignored. Duplicate name/key/index/constraint exceptions occur because the DDL generated by DBMS_METADATA results in some objects being created more than once. Exceptions also arise when re-creating constraints if the required permissions have not been granted to the target schema . Exceptions are raised if the source schema uses Oracle Advanced Queuing (AQ). When AQ is present in the source DBMS_METADATA generates operations that cannot be replayed in the target schemas, even by a DBA. Any exceptions that arise while replaying the DDL statements are caught, classified as IGNOREABLE, DUPLICATE, REFERENCE WARNING, AQ_RELATED, or FATAL and logged. The log of DDL operations can be queried by applying a table operator to the IMPORT_DDL_LOG function. EXPORT_SCHEMA and IMPORT_JSON are now theoretically capable of cloning any database schema. The next post will examine what occurs when attempting to clone each of the six Oracle supplied sample schemas.","@type":"BlogPosting","url":"http://localhost:4000/json/import/export/oracle/2018/06/21/DDL-Operations.html","headline":"Schema DDL operations","dateModified":"2018-06-21T18:00:00-07:00","datePublished":"2018-06-21T18:00:00-07:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/json/import/export/oracle/2018/06/21/DDL-Operations.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="JSON Exchange" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">JSON Exchange</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Schema DDL operations</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2018-06-21T18:00:00-07:00" itemprop="datePublished">Jun 21, 2018
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <h2 id="adding-ddl-operations-in-the-export-file">Adding DDL operations in the export file.</h2>

<p>The previous post described a package for importing data from the files generated by JSON_EXPORT. It also described a method for testing this package which relied on using Oracle’s classing export (exp) and import(imp) utilities to  create an empty clone of a database schema. The method works for the HR schema, Unfortunately when it applied to the  other sample schemas, a number of errors are reported during the import operation, including illegal identifiers and unsupported data types. Clearly another solution to duplicating a schema’s structure is required.</p>

<p>This post introduces the PL/SQL package JSON_EXPORT_DDL. This package provides two functions. The first, FETCH_DDL_STATEMENTS, returns the set of DDL statements used to create all of the objects in the schema. The second, APPLY_DDL_STATEMENTS replays the DDL captured by FETCH_DLL_STATEMENTS in the target schema, effective turning the target schema into a structural clone of the source schema.</p>

<p>The FETCH_DDL_STATEMENTS function uses the Oracle supplied package DBMS_METADATA  to obtain the set of DLL operations used to create the source schema. The order in which DDL Operations are exported is as follows</p>

<ol>
  <li>XML Schemas, generated using DBMS_METADATA. XML Schemas must be registered in the target schema before attempting to perform DDL operations.</li>
  <li>DLL Operations, generated using DBMS_METADATA. DBMS_METADATA is configured to omit storage clauses making it much easier to replay the DLL operations in the target environment.</li>
  <li>DMS_XDBZ.enableHierarchy() operations. This re-establishes any relationship between an XMLType table and the XML DB repository.</li>
  <li>Index naming operations. This ensure that system generated index names from the source schema are preserved in the target schema.</li>
</ol>

<p>The code used to access the DDL operations is shown below</p>

<pre><code class="language-SQL">  begin
    V_HDL_OPEN := DBMS_METADATA.OPEN('SCHEMA_EXPORT');
    DBMS_METADATA.SET_FILTER(V_HDL_OPEN,'SCHEMA',P_SCHEMA);

    V_HDL_TRANSFORM := DBMS_METADATA.ADD_TRANSFORM(V_HDL_OPEN,'DDL');

    -- Suppress Segement information for TABLES, INDEXES and CONSTRAINTS

    DBMS_METADATA.SET_TRANSFORM_PARAM(V_HDL_TRANSFORM,'SEGMENT_ATTRIBUTES',false,'TABLE');
    DBMS_METADATA.SET_TRANSFORM_PARAM(V_HDL_TRANSFORM,'SEGMENT_ATTRIBUTES',false,'INDEX');
    DBMS_METADATA.SET_TRANSFORM_PARAM(V_HDL_TRANSFORM,'SEGMENT_ATTRIBUTES',false,'CONSTRAINT');

    -- Return constraints as 'ALTER TABLE' operations

    DBMS_METADATA.SET_TRANSFORM_PARAM(V_HDL_TRANSFORM,'CONSTRAINTS_AS_ALTER',true,'TABLE');
    DBMS_METADATA.SET_TRANSFORM_PARAM(V_HDL_TRANSFORM,'REF_CONSTRAINTS',false,'TABLE');

    -- Exclude XML Schema Info. XML Schemas need to come first and 
    -- are handled in a seperate section

    DBMS_METADATA.SET_FILTER(V_HDL_OPEN,'EXCLUDE_PATH_EXPR','=''XMLSCHEMA''');

    loop
      -- Get the next batch of DDL_STATEMENTS. Each batch may contain zero or more statements.
      V_DDL_STATEMENTS := DBMS_METADATA.FETCH_DDL(V_HDL_OPEN);
	  EXIT WHEN V_DDL_STATEMENTS IS NULL;

      for i in 1 .. V_DDL_STATEMENTS.count loop

  	    V_DDL_STATEMENT := V_DDL_STATEMENTS(i).DDLTEXT;

  	    -- Strip leading and trailing white space from DDL statement
	    V_DDL_STATEMENT := TRIM(BOTH C_NEWLINE FROM V_DDL_STATEMENT);
        V_DDL_STATEMENT := TRIM(BOTH C_CARRIAGE_RETURN FROM V_DDL_STATEMENT);
        V_DDL_STATEMENT := TRIM(V_DDL_STATEMENT);

        PIPE ROW (TRIM(V_DDL_STATEMENT));
      end loop;
    end loop;
</code></pre>

<p>The EXPORT_SCHEMA function inserts a “ddl” object into the export file immediately after the “systemInformation” object. The “ddl” object is created based on the DDL statements returned by FETCH_DLL_STATEMENTS. The “ddl” object is an array, each item in the array contains a single ddl operation.</p>

<p>The IMPORT_JSON function passes the export file to APPLY_DDL_STATEMENTS before attempting to import data. This function uses JSON_TABLE to extract each of the ddl statements from the dump and executes them in order.Before replaying a DDL operation all references to the source schema are replaced with references to the target schema. This enables cloning from schema A to schema B.</p>

<p>Exceptions may be raised while replaying the DDL generated by DBMS_METADATA.  In most cases these can be safely ignored. Duplicate name/key/index/constraint exceptions occur because the DDL generated by DBMS_METADATA results in some objects being created more than once.  Exceptions also  arise when re-creating constraints if the required permissions have not been granted to the target schema . Exceptions are raised if the source schema uses Oracle Advanced Queuing (AQ). When AQ is present in the source DBMS_METADATA generates operations that cannot be  replayed in the target schemas, even by a  DBA.  Any exceptions that arise while replaying the DDL statements are caught, classified as IGNOREABLE, DUPLICATE, REFERENCE  WARNING, AQ_RELATED, or FATAL and logged.</p>

<p>The log of DDL operations can be queried by applying a table operator to the IMPORT_DDL_LOG function.</p>

<p>EXPORT_SCHEMA and IMPORT_JSON are now theoretically capable of cloning any database schema. The next post will examine what occurs when attempting to clone each of the six Oracle supplied sample schemas.</p>

  </div><a class="u-url" href="/json/import/export/oracle/2018/06/21/DDL-Operations.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">JSON Exchange</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">JSON Exchange</li><li><a class="u-email" href="mailto:mdd@appdev4db.com">mdd@appdev4db.com</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/markddrake"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">markddrake</span></a></li><li><a href="https://www.twitter.com/markddrake"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">markddrake</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>A simple utility for exporting and importing data using JSON</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
