<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Unsupported Data Types (Part 1) | JSON Exchange</title>
<meta name="generator" content="Jekyll v3.8.3" />
<meta property="og:title" content="Unsupported Data Types (Part 1)" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="The Devil’s in the Details: Unsupported scalar data types In the previous post, the first attempt to run EXPORT_SCHEMA on the SH schema failed due to fact one of the tables contained a BLOB column. Fortunately, in that case of the SH schema, the BLOB column was in a table that needed to be excluded from the export operation, and all remaining tables in the SH schema use data types that are directly supported by the JSON_ARRAY operator However that incident was simply a precursor for the problems that are encountered when attempting to process the OE schema. SQL&gt; select JSON_EXPORT.EXPORT_SCHEMA(&#39;OE&#39;) from dual; ERROR: ORA-40654: Input to JSON generation function has unsupported data type. ORA-06512: at &quot;SYSTEM.JSON_EXPORT&quot;, line 197 In order to determine the set of data types supported by JSON_ARRAY in each database release a simple script was developed. The script creates a table containing one column for each possible scalar data type, insert 1 row of data into the tables and then attempts to perform a JSON_ARRAY operation on each column. The script, DATA_TYPE_TEST.sql can be found on GitHub in the project’s test directory. The results of running this script on 12.2 and 18.1 are documented in the following table. Data Type 12cR2 18S SQL Workaround CHAR (BYTE semantics)`` ✔️ ✔️   CHAR (CHAR semantics :heavy_check_mark: ✔️   VARCHAR2 (Byte Semantics) ✔️ ✔️   VARCHAR2 (Char Semantics) ✔️ ✔️   NCHAR ❗️ ✔️   NVARCHAR ❗️ ✔️   NUMBER ✔️ ✔️   NUMBER (Precision) ✔️ ✔️   NUMBER (Precision,Scale) ✔️ ✔️   BINARY FLOAT ❌ ✔️ TO_CHAR BINARY DECIMAL ❌ ✔️ TO_CHAR DATE ✔️ ✔️   TIMESTAMP ✔️ ✔️   TIMESTAMP WITH TIME ZONE ✔️ ✔️   TIMESTAMP WITH LOCAL TIME ZONE ❌ ✔️ SYS_EXTRACT_UTC INTERVAL YEAR TO MONTH ❌ ✔️ Custom SQL INTERVAL DAY TO SECOND ❌ ✔️ Custom SQL RAW ✔️ ✔️   ROWID ❌ ❌ ROWIDTOCHAR UROWID ❌ ❌ ROWIDTOCHAR BLOB ❗️ ✔️   CLOB ✔️ ✔️   NCLOB ❗️ ✔️   BFILE ❌ ❌   XMLTYPE ❌ ❌ XMLSEQUENCE LONG ❌ ❌   LONG RAW ❌ ❌   The script also demonstrates potential solutions for some of the data types that are not supported natively. ❗️ The JSON_ARRAY documentation for Oracle 12.2 clearly states that BLOB is not a supported data type. However, as is shown by the DATA_TYPE_TESTS.sql script, if a BLOB is passed to the JSON_ARRAY operator it does not raise the expected “ORA-40654: Input to JSON generation function has unsupported data type” exception. Rather it mistakenly assumes that the BLOB column contains textual data and attempts to process the content as text. If the BLOB contains binary data this will typically result in the exception “ORA-40474: invalid UTF-8 byte sequence in JSON data” being raised by JSON_ARRAY. In Oracle 18c the BLOB data type is supported by JSON_ARRAY. When a BLOB is passed to JSON_ARRAY a HEXBINARY encoded representation of the BLOB’s content is returned by the JSON_ARRAY operator. ❗️There is a similar issue with the way in which JSON_ARRAY handles of NCHAR, NVARCHAR2 and NCLOB in database 12.2 which can also result in exception “ORA-40474: invalid UTF-8 byte sequence in JSON data” being raised. A possible workaround for this, at least in databases configured to use ‘AL32UTF8’ as the database character set, is to apply the TO_CHAR or TO_CLOB operator to the column before passing it to the JSON_ARRAY operator. Note that it is likely that this workaround will fail in non AL32UTF8 environments. Running the DATA_TYPE_TESTS.sql script in Oracle 18 conforms native support for Interval data types, and the value of an Interval column is output in a format compliant with the ISO 8601 standard. In order to support Interval data types in Oracle12.2 it is necessary to use the SQL extract function to decompose the interval value into discrete components and then construct a string that mimics the native support provided by Oracle 18. Implementing the workarounds requires modifying the column list generated by GENERATE_STATEMENT to incorporate the appropriate workarounds. A case statement, based on the DATA_TYPE column, is used to apply each workaround when generating the list of columns names. Conditional compilation is used to determine which workarounds are required in which database version. The result of implementing this logic is the query is now generates the “select list” required to export the table’s content as JSON, rather than a list of the columns in the table. The case statement required to generate the select list is shown below case -- For some reason RAW columns have DATA_TYPE_OWNER set to the current schema and -- the condition DATA_TYPE_OWNER is not NULL is requried to identify OBJECT types when DATA_TYPE = &#39;RAW&#39; then &#39;&quot;&#39; || COLUMN_NAME || &#39;&quot;&#39; $IF NOT JSON_FEATURE_DETECTION.CLOB_SUPPORTED $THEN /* ** Pre 18.1 Some Scalar Data Types are not natively supported by JSON_ARRAY() */ when DATA_TYPE in (&#39;BINARY_DOUBLE&#39;,&#39;BINARY_FLOAT&#39;) then &#39;TO_CHAR(&quot;&#39; || COLUMN_NAME || &#39;&quot;)&#39; when DATA_TYPE LIKE &#39;TIMESTAMP%WITH LOCAL TIME ZONE&#39; then &#39;TO_CHAR(SYS_EXTRACT_UTC(&quot;&#39; || COLUMN_NAME || &#39;&quot;),&#39;&#39;IYYY-MM-DD&quot;T&quot;HH24:MI:SS.FF9&quot;Z&quot;&#39;&#39;)&#39; when DATA_TYPE LIKE &#39;INTERVAL DAY% TO SECOND%&#39; then &#39;&#39;&#39;P&#39;&#39; || extract(DAY FROM &quot;&#39; || COLUMN_NAME || &#39;&quot;) || &#39;&#39;D&#39;&#39; || &#39;&#39;T&#39;&#39; || case when extract(HOUR FROM &quot;&#39; || COLUMN_NAME || &#39;&quot;) &lt;&gt; 0 then extract(HOUR FROM &quot;&#39; || COLUMN_NAME || &#39;&quot;) || &#39;&#39;H&#39;&#39; end || case when extract(MINUTE FROM &quot;&#39; || COLUMN_NAME || &#39;&quot;) &lt;&gt; 0 then extract(MINUTE FROM &quot;&#39; || COLUMN_NAME || &#39;&quot;) || &#39;&#39;M&#39;&#39; end || case when extract(SECOND FROM &quot;&#39; || COLUMN_NAME || &#39;&quot;) &lt;&gt; 0 then extract(SECOND FROM &quot;&#39; || COLUMN_NAME || &#39;&quot;) || &#39;&#39;S&#39;&#39; end&#39; when DATA_TYPE LIKE &#39;INTERVAL YEAR% TO MONTH%&#39; then &#39;&#39;&#39;P&#39;&#39; || extract(YEAR FROM &quot;&#39; || COLUMN_NAME || &#39;&quot;) || &#39;&#39;Y&#39;&#39; || case when extract(MONTH FROM &quot;&#39; || COLUMN_NAME || &#39;&quot;) &lt;&gt; 0 then extract(MONTH FROM &quot;&#39; || COLUMN_NAME || &#39;&quot;) || &#39;&#39;M&#39;&#39; end&#39; when DATA_TYPE in (&#39;NCHAR&#39;,&#39;NVARCHAR2&#39;) then &#39;TO_CHAR(&quot;&#39; || COLUMN_NAME || &#39;&quot;)&#39; when DATA_TYPE = &#39;NCLOB&#39; then &#39;TO_CLOB(&quot;&#39; || COLUMN_NAME || &#39;&quot;)&#39; $END /* ** Quick Fixes for datatypes not natively supported */ when DATA_TYPE = &#39;XMLTYPE&#39; -- Can be owned by SYS or PUBLIC then &#39;case when &quot;&#39; || COLUMN_NAME || &#39;&quot; is NULL then NULL else XMLSERIALIZE(CONTENT &quot;&#39; || COLUMN_NAME || &#39;&quot; as CLOB) end&#39; when DATA_TYPE = &#39;ROWID&#39; or DATA_TYPE = &#39;UROWID&#39; then &#39;ROWIDTOCHAR(&quot;&#39; || COLUMN_NAME || &#39;&quot;)&#39; /* ** Comment outunsupported scalar data types and Object types */ when DATA_TYPE in (&#39;LONG&#39;,&#39;LONG RAW&#39;,&#39;BFILE&#39;,&#39;BLOB&#39;) then &#39;&#39;&#39;&quot;&#39; || COLUMN_NAME || &#39;&quot;. Unsupported data type [&quot;&#39; || DATA_TYPE || &#39;&quot;]&#39;&#39;&#39; when DATA_TYPE_OWNER is not NULL then &#39;&#39;&#39;&quot;&#39; || COLUMN_NAME || &#39;&quot;. Unsupported object type [&quot;&#39; || DATA_TYPE_OWNER || &#39;&quot;.&quot;&#39; || DATA_TYPE || &#39;&quot;]&#39;&#39;&#39; else &#39;&quot;&#39; || COLUMN_NAME || &#39;&quot;&#39; The above implementation assumes that applying the patch to enable CLOB support to Database 12.2 will also extend the list of data types supported natively by JSON_ARRAY in 12.2. If this is not the case further ‘DUCK TYPING’ may be necessary to determine which data types are supported natively in which database release in order to generate a correctly optimized column list. After implementing these changes an EXPORT_SCHEMA operation on the OE schema succeeds. However a closer examination of the JSON document generated shows that the export failed to export all of the data in the schema The following table shows the results of the export operation Table Name Results Cause INVENTORIES ✔️   ORDERS ✔️   ORDER_ITEMS ✔️   PROMOTIONS ✔️   PROCUCT_INFORMATION ✔️   CUSTOMERS ❌ Unsupported OBJECT Type Column WAREHOUSES ❌ Unsupported OBJECT Type Column CATEOGORIES ❌ Skipped OBJECT Table PURCHASEORDER ❌ Skipped OBJECT (XMLTYPE) Table At this point EXPORT_SCHEMA is capable of handling most of the common scalar data types supported by the Oracle Database. The next post will explain how in-line PL/SQL procedures can be used to enable support for BIFLE and BLOB data types." />
<meta property="og:description" content="The Devil’s in the Details: Unsupported scalar data types In the previous post, the first attempt to run EXPORT_SCHEMA on the SH schema failed due to fact one of the tables contained a BLOB column. Fortunately, in that case of the SH schema, the BLOB column was in a table that needed to be excluded from the export operation, and all remaining tables in the SH schema use data types that are directly supported by the JSON_ARRAY operator However that incident was simply a precursor for the problems that are encountered when attempting to process the OE schema. SQL&gt; select JSON_EXPORT.EXPORT_SCHEMA(&#39;OE&#39;) from dual; ERROR: ORA-40654: Input to JSON generation function has unsupported data type. ORA-06512: at &quot;SYSTEM.JSON_EXPORT&quot;, line 197 In order to determine the set of data types supported by JSON_ARRAY in each database release a simple script was developed. The script creates a table containing one column for each possible scalar data type, insert 1 row of data into the tables and then attempts to perform a JSON_ARRAY operation on each column. The script, DATA_TYPE_TEST.sql can be found on GitHub in the project’s test directory. The results of running this script on 12.2 and 18.1 are documented in the following table. Data Type 12cR2 18S SQL Workaround CHAR (BYTE semantics)`` ✔️ ✔️   CHAR (CHAR semantics :heavy_check_mark: ✔️   VARCHAR2 (Byte Semantics) ✔️ ✔️   VARCHAR2 (Char Semantics) ✔️ ✔️   NCHAR ❗️ ✔️   NVARCHAR ❗️ ✔️   NUMBER ✔️ ✔️   NUMBER (Precision) ✔️ ✔️   NUMBER (Precision,Scale) ✔️ ✔️   BINARY FLOAT ❌ ✔️ TO_CHAR BINARY DECIMAL ❌ ✔️ TO_CHAR DATE ✔️ ✔️   TIMESTAMP ✔️ ✔️   TIMESTAMP WITH TIME ZONE ✔️ ✔️   TIMESTAMP WITH LOCAL TIME ZONE ❌ ✔️ SYS_EXTRACT_UTC INTERVAL YEAR TO MONTH ❌ ✔️ Custom SQL INTERVAL DAY TO SECOND ❌ ✔️ Custom SQL RAW ✔️ ✔️   ROWID ❌ ❌ ROWIDTOCHAR UROWID ❌ ❌ ROWIDTOCHAR BLOB ❗️ ✔️   CLOB ✔️ ✔️   NCLOB ❗️ ✔️   BFILE ❌ ❌   XMLTYPE ❌ ❌ XMLSEQUENCE LONG ❌ ❌   LONG RAW ❌ ❌   The script also demonstrates potential solutions for some of the data types that are not supported natively. ❗️ The JSON_ARRAY documentation for Oracle 12.2 clearly states that BLOB is not a supported data type. However, as is shown by the DATA_TYPE_TESTS.sql script, if a BLOB is passed to the JSON_ARRAY operator it does not raise the expected “ORA-40654: Input to JSON generation function has unsupported data type” exception. Rather it mistakenly assumes that the BLOB column contains textual data and attempts to process the content as text. If the BLOB contains binary data this will typically result in the exception “ORA-40474: invalid UTF-8 byte sequence in JSON data” being raised by JSON_ARRAY. In Oracle 18c the BLOB data type is supported by JSON_ARRAY. When a BLOB is passed to JSON_ARRAY a HEXBINARY encoded representation of the BLOB’s content is returned by the JSON_ARRAY operator. ❗️There is a similar issue with the way in which JSON_ARRAY handles of NCHAR, NVARCHAR2 and NCLOB in database 12.2 which can also result in exception “ORA-40474: invalid UTF-8 byte sequence in JSON data” being raised. A possible workaround for this, at least in databases configured to use ‘AL32UTF8’ as the database character set, is to apply the TO_CHAR or TO_CLOB operator to the column before passing it to the JSON_ARRAY operator. Note that it is likely that this workaround will fail in non AL32UTF8 environments. Running the DATA_TYPE_TESTS.sql script in Oracle 18 conforms native support for Interval data types, and the value of an Interval column is output in a format compliant with the ISO 8601 standard. In order to support Interval data types in Oracle12.2 it is necessary to use the SQL extract function to decompose the interval value into discrete components and then construct a string that mimics the native support provided by Oracle 18. Implementing the workarounds requires modifying the column list generated by GENERATE_STATEMENT to incorporate the appropriate workarounds. A case statement, based on the DATA_TYPE column, is used to apply each workaround when generating the list of columns names. Conditional compilation is used to determine which workarounds are required in which database version. The result of implementing this logic is the query is now generates the “select list” required to export the table’s content as JSON, rather than a list of the columns in the table. The case statement required to generate the select list is shown below case -- For some reason RAW columns have DATA_TYPE_OWNER set to the current schema and -- the condition DATA_TYPE_OWNER is not NULL is requried to identify OBJECT types when DATA_TYPE = &#39;RAW&#39; then &#39;&quot;&#39; || COLUMN_NAME || &#39;&quot;&#39; $IF NOT JSON_FEATURE_DETECTION.CLOB_SUPPORTED $THEN /* ** Pre 18.1 Some Scalar Data Types are not natively supported by JSON_ARRAY() */ when DATA_TYPE in (&#39;BINARY_DOUBLE&#39;,&#39;BINARY_FLOAT&#39;) then &#39;TO_CHAR(&quot;&#39; || COLUMN_NAME || &#39;&quot;)&#39; when DATA_TYPE LIKE &#39;TIMESTAMP%WITH LOCAL TIME ZONE&#39; then &#39;TO_CHAR(SYS_EXTRACT_UTC(&quot;&#39; || COLUMN_NAME || &#39;&quot;),&#39;&#39;IYYY-MM-DD&quot;T&quot;HH24:MI:SS.FF9&quot;Z&quot;&#39;&#39;)&#39; when DATA_TYPE LIKE &#39;INTERVAL DAY% TO SECOND%&#39; then &#39;&#39;&#39;P&#39;&#39; || extract(DAY FROM &quot;&#39; || COLUMN_NAME || &#39;&quot;) || &#39;&#39;D&#39;&#39; || &#39;&#39;T&#39;&#39; || case when extract(HOUR FROM &quot;&#39; || COLUMN_NAME || &#39;&quot;) &lt;&gt; 0 then extract(HOUR FROM &quot;&#39; || COLUMN_NAME || &#39;&quot;) || &#39;&#39;H&#39;&#39; end || case when extract(MINUTE FROM &quot;&#39; || COLUMN_NAME || &#39;&quot;) &lt;&gt; 0 then extract(MINUTE FROM &quot;&#39; || COLUMN_NAME || &#39;&quot;) || &#39;&#39;M&#39;&#39; end || case when extract(SECOND FROM &quot;&#39; || COLUMN_NAME || &#39;&quot;) &lt;&gt; 0 then extract(SECOND FROM &quot;&#39; || COLUMN_NAME || &#39;&quot;) || &#39;&#39;S&#39;&#39; end&#39; when DATA_TYPE LIKE &#39;INTERVAL YEAR% TO MONTH%&#39; then &#39;&#39;&#39;P&#39;&#39; || extract(YEAR FROM &quot;&#39; || COLUMN_NAME || &#39;&quot;) || &#39;&#39;Y&#39;&#39; || case when extract(MONTH FROM &quot;&#39; || COLUMN_NAME || &#39;&quot;) &lt;&gt; 0 then extract(MONTH FROM &quot;&#39; || COLUMN_NAME || &#39;&quot;) || &#39;&#39;M&#39;&#39; end&#39; when DATA_TYPE in (&#39;NCHAR&#39;,&#39;NVARCHAR2&#39;) then &#39;TO_CHAR(&quot;&#39; || COLUMN_NAME || &#39;&quot;)&#39; when DATA_TYPE = &#39;NCLOB&#39; then &#39;TO_CLOB(&quot;&#39; || COLUMN_NAME || &#39;&quot;)&#39; $END /* ** Quick Fixes for datatypes not natively supported */ when DATA_TYPE = &#39;XMLTYPE&#39; -- Can be owned by SYS or PUBLIC then &#39;case when &quot;&#39; || COLUMN_NAME || &#39;&quot; is NULL then NULL else XMLSERIALIZE(CONTENT &quot;&#39; || COLUMN_NAME || &#39;&quot; as CLOB) end&#39; when DATA_TYPE = &#39;ROWID&#39; or DATA_TYPE = &#39;UROWID&#39; then &#39;ROWIDTOCHAR(&quot;&#39; || COLUMN_NAME || &#39;&quot;)&#39; /* ** Comment outunsupported scalar data types and Object types */ when DATA_TYPE in (&#39;LONG&#39;,&#39;LONG RAW&#39;,&#39;BFILE&#39;,&#39;BLOB&#39;) then &#39;&#39;&#39;&quot;&#39; || COLUMN_NAME || &#39;&quot;. Unsupported data type [&quot;&#39; || DATA_TYPE || &#39;&quot;]&#39;&#39;&#39; when DATA_TYPE_OWNER is not NULL then &#39;&#39;&#39;&quot;&#39; || COLUMN_NAME || &#39;&quot;. Unsupported object type [&quot;&#39; || DATA_TYPE_OWNER || &#39;&quot;.&quot;&#39; || DATA_TYPE || &#39;&quot;]&#39;&#39;&#39; else &#39;&quot;&#39; || COLUMN_NAME || &#39;&quot;&#39; The above implementation assumes that applying the patch to enable CLOB support to Database 12.2 will also extend the list of data types supported natively by JSON_ARRAY in 12.2. If this is not the case further ‘DUCK TYPING’ may be necessary to determine which data types are supported natively in which database release in order to generate a correctly optimized column list. After implementing these changes an EXPORT_SCHEMA operation on the OE schema succeeds. However a closer examination of the JSON document generated shows that the export failed to export all of the data in the schema The following table shows the results of the export operation Table Name Results Cause INVENTORIES ✔️   ORDERS ✔️   ORDER_ITEMS ✔️   PROMOTIONS ✔️   PROCUCT_INFORMATION ✔️   CUSTOMERS ❌ Unsupported OBJECT Type Column WAREHOUSES ❌ Unsupported OBJECT Type Column CATEOGORIES ❌ Skipped OBJECT Table PURCHASEORDER ❌ Skipped OBJECT (XMLTYPE) Table At this point EXPORT_SCHEMA is capable of handling most of the common scalar data types supported by the Oracle Database. The next post will explain how in-line PL/SQL procedures can be used to enable support for BIFLE and BLOB data types." />
<link rel="canonical" href="http://localhost:4000/json/export/import/oracle/2018/06/16/Unsupported-Scalar-Types.html" />
<meta property="og:url" content="http://localhost:4000/json/export/import/oracle/2018/06/16/Unsupported-Scalar-Types.html" />
<meta property="og:site_name" content="JSON Exchange" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2018-06-16T18:00:00-07:00" />
<script type="application/ld+json">
{"description":"The Devil’s in the Details: Unsupported scalar data types In the previous post, the first attempt to run EXPORT_SCHEMA on the SH schema failed due to fact one of the tables contained a BLOB column. Fortunately, in that case of the SH schema, the BLOB column was in a table that needed to be excluded from the export operation, and all remaining tables in the SH schema use data types that are directly supported by the JSON_ARRAY operator However that incident was simply a precursor for the problems that are encountered when attempting to process the OE schema. SQL&gt; select JSON_EXPORT.EXPORT_SCHEMA(&#39;OE&#39;) from dual; ERROR: ORA-40654: Input to JSON generation function has unsupported data type. ORA-06512: at &quot;SYSTEM.JSON_EXPORT&quot;, line 197 In order to determine the set of data types supported by JSON_ARRAY in each database release a simple script was developed. The script creates a table containing one column for each possible scalar data type, insert 1 row of data into the tables and then attempts to perform a JSON_ARRAY operation on each column. The script, DATA_TYPE_TEST.sql can be found on GitHub in the project’s test directory. The results of running this script on 12.2 and 18.1 are documented in the following table. Data Type 12cR2 18S SQL Workaround CHAR (BYTE semantics)`` ✔️ ✔️   CHAR (CHAR semantics :heavy_check_mark: ✔️   VARCHAR2 (Byte Semantics) ✔️ ✔️   VARCHAR2 (Char Semantics) ✔️ ✔️   NCHAR ❗️ ✔️   NVARCHAR ❗️ ✔️   NUMBER ✔️ ✔️   NUMBER (Precision) ✔️ ✔️   NUMBER (Precision,Scale) ✔️ ✔️   BINARY FLOAT ❌ ✔️ TO_CHAR BINARY DECIMAL ❌ ✔️ TO_CHAR DATE ✔️ ✔️   TIMESTAMP ✔️ ✔️   TIMESTAMP WITH TIME ZONE ✔️ ✔️   TIMESTAMP WITH LOCAL TIME ZONE ❌ ✔️ SYS_EXTRACT_UTC INTERVAL YEAR TO MONTH ❌ ✔️ Custom SQL INTERVAL DAY TO SECOND ❌ ✔️ Custom SQL RAW ✔️ ✔️   ROWID ❌ ❌ ROWIDTOCHAR UROWID ❌ ❌ ROWIDTOCHAR BLOB ❗️ ✔️   CLOB ✔️ ✔️   NCLOB ❗️ ✔️   BFILE ❌ ❌   XMLTYPE ❌ ❌ XMLSEQUENCE LONG ❌ ❌   LONG RAW ❌ ❌   The script also demonstrates potential solutions for some of the data types that are not supported natively. ❗️ The JSON_ARRAY documentation for Oracle 12.2 clearly states that BLOB is not a supported data type. However, as is shown by the DATA_TYPE_TESTS.sql script, if a BLOB is passed to the JSON_ARRAY operator it does not raise the expected “ORA-40654: Input to JSON generation function has unsupported data type” exception. Rather it mistakenly assumes that the BLOB column contains textual data and attempts to process the content as text. If the BLOB contains binary data this will typically result in the exception “ORA-40474: invalid UTF-8 byte sequence in JSON data” being raised by JSON_ARRAY. In Oracle 18c the BLOB data type is supported by JSON_ARRAY. When a BLOB is passed to JSON_ARRAY a HEXBINARY encoded representation of the BLOB’s content is returned by the JSON_ARRAY operator. ❗️There is a similar issue with the way in which JSON_ARRAY handles of NCHAR, NVARCHAR2 and NCLOB in database 12.2 which can also result in exception “ORA-40474: invalid UTF-8 byte sequence in JSON data” being raised. A possible workaround for this, at least in databases configured to use ‘AL32UTF8’ as the database character set, is to apply the TO_CHAR or TO_CLOB operator to the column before passing it to the JSON_ARRAY operator. Note that it is likely that this workaround will fail in non AL32UTF8 environments. Running the DATA_TYPE_TESTS.sql script in Oracle 18 conforms native support for Interval data types, and the value of an Interval column is output in a format compliant with the ISO 8601 standard. In order to support Interval data types in Oracle12.2 it is necessary to use the SQL extract function to decompose the interval value into discrete components and then construct a string that mimics the native support provided by Oracle 18. Implementing the workarounds requires modifying the column list generated by GENERATE_STATEMENT to incorporate the appropriate workarounds. A case statement, based on the DATA_TYPE column, is used to apply each workaround when generating the list of columns names. Conditional compilation is used to determine which workarounds are required in which database version. The result of implementing this logic is the query is now generates the “select list” required to export the table’s content as JSON, rather than a list of the columns in the table. The case statement required to generate the select list is shown below case -- For some reason RAW columns have DATA_TYPE_OWNER set to the current schema and -- the condition DATA_TYPE_OWNER is not NULL is requried to identify OBJECT types when DATA_TYPE = &#39;RAW&#39; then &#39;&quot;&#39; || COLUMN_NAME || &#39;&quot;&#39; $IF NOT JSON_FEATURE_DETECTION.CLOB_SUPPORTED $THEN /* ** Pre 18.1 Some Scalar Data Types are not natively supported by JSON_ARRAY() */ when DATA_TYPE in (&#39;BINARY_DOUBLE&#39;,&#39;BINARY_FLOAT&#39;) then &#39;TO_CHAR(&quot;&#39; || COLUMN_NAME || &#39;&quot;)&#39; when DATA_TYPE LIKE &#39;TIMESTAMP%WITH LOCAL TIME ZONE&#39; then &#39;TO_CHAR(SYS_EXTRACT_UTC(&quot;&#39; || COLUMN_NAME || &#39;&quot;),&#39;&#39;IYYY-MM-DD&quot;T&quot;HH24:MI:SS.FF9&quot;Z&quot;&#39;&#39;)&#39; when DATA_TYPE LIKE &#39;INTERVAL DAY% TO SECOND%&#39; then &#39;&#39;&#39;P&#39;&#39; || extract(DAY FROM &quot;&#39; || COLUMN_NAME || &#39;&quot;) || &#39;&#39;D&#39;&#39; || &#39;&#39;T&#39;&#39; || case when extract(HOUR FROM &quot;&#39; || COLUMN_NAME || &#39;&quot;) &lt;&gt; 0 then extract(HOUR FROM &quot;&#39; || COLUMN_NAME || &#39;&quot;) || &#39;&#39;H&#39;&#39; end || case when extract(MINUTE FROM &quot;&#39; || COLUMN_NAME || &#39;&quot;) &lt;&gt; 0 then extract(MINUTE FROM &quot;&#39; || COLUMN_NAME || &#39;&quot;) || &#39;&#39;M&#39;&#39; end || case when extract(SECOND FROM &quot;&#39; || COLUMN_NAME || &#39;&quot;) &lt;&gt; 0 then extract(SECOND FROM &quot;&#39; || COLUMN_NAME || &#39;&quot;) || &#39;&#39;S&#39;&#39; end&#39; when DATA_TYPE LIKE &#39;INTERVAL YEAR% TO MONTH%&#39; then &#39;&#39;&#39;P&#39;&#39; || extract(YEAR FROM &quot;&#39; || COLUMN_NAME || &#39;&quot;) || &#39;&#39;Y&#39;&#39; || case when extract(MONTH FROM &quot;&#39; || COLUMN_NAME || &#39;&quot;) &lt;&gt; 0 then extract(MONTH FROM &quot;&#39; || COLUMN_NAME || &#39;&quot;) || &#39;&#39;M&#39;&#39; end&#39; when DATA_TYPE in (&#39;NCHAR&#39;,&#39;NVARCHAR2&#39;) then &#39;TO_CHAR(&quot;&#39; || COLUMN_NAME || &#39;&quot;)&#39; when DATA_TYPE = &#39;NCLOB&#39; then &#39;TO_CLOB(&quot;&#39; || COLUMN_NAME || &#39;&quot;)&#39; $END /* ** Quick Fixes for datatypes not natively supported */ when DATA_TYPE = &#39;XMLTYPE&#39; -- Can be owned by SYS or PUBLIC then &#39;case when &quot;&#39; || COLUMN_NAME || &#39;&quot; is NULL then NULL else XMLSERIALIZE(CONTENT &quot;&#39; || COLUMN_NAME || &#39;&quot; as CLOB) end&#39; when DATA_TYPE = &#39;ROWID&#39; or DATA_TYPE = &#39;UROWID&#39; then &#39;ROWIDTOCHAR(&quot;&#39; || COLUMN_NAME || &#39;&quot;)&#39; /* ** Comment outunsupported scalar data types and Object types */ when DATA_TYPE in (&#39;LONG&#39;,&#39;LONG RAW&#39;,&#39;BFILE&#39;,&#39;BLOB&#39;) then &#39;&#39;&#39;&quot;&#39; || COLUMN_NAME || &#39;&quot;. Unsupported data type [&quot;&#39; || DATA_TYPE || &#39;&quot;]&#39;&#39;&#39; when DATA_TYPE_OWNER is not NULL then &#39;&#39;&#39;&quot;&#39; || COLUMN_NAME || &#39;&quot;. Unsupported object type [&quot;&#39; || DATA_TYPE_OWNER || &#39;&quot;.&quot;&#39; || DATA_TYPE || &#39;&quot;]&#39;&#39;&#39; else &#39;&quot;&#39; || COLUMN_NAME || &#39;&quot;&#39; The above implementation assumes that applying the patch to enable CLOB support to Database 12.2 will also extend the list of data types supported natively by JSON_ARRAY in 12.2. If this is not the case further ‘DUCK TYPING’ may be necessary to determine which data types are supported natively in which database release in order to generate a correctly optimized column list. After implementing these changes an EXPORT_SCHEMA operation on the OE schema succeeds. However a closer examination of the JSON document generated shows that the export failed to export all of the data in the schema The following table shows the results of the export operation Table Name Results Cause INVENTORIES ✔️   ORDERS ✔️   ORDER_ITEMS ✔️   PROMOTIONS ✔️   PROCUCT_INFORMATION ✔️   CUSTOMERS ❌ Unsupported OBJECT Type Column WAREHOUSES ❌ Unsupported OBJECT Type Column CATEOGORIES ❌ Skipped OBJECT Table PURCHASEORDER ❌ Skipped OBJECT (XMLTYPE) Table At this point EXPORT_SCHEMA is capable of handling most of the common scalar data types supported by the Oracle Database. The next post will explain how in-line PL/SQL procedures can be used to enable support for BIFLE and BLOB data types.","@type":"BlogPosting","url":"http://localhost:4000/json/export/import/oracle/2018/06/16/Unsupported-Scalar-Types.html","headline":"Unsupported Data Types (Part 1)","dateModified":"2018-06-16T18:00:00-07:00","datePublished":"2018-06-16T18:00:00-07:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/json/export/import/oracle/2018/06/16/Unsupported-Scalar-Types.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="JSON Exchange" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">JSON Exchange</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Unsupported Data Types (Part 1)</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2018-06-16T18:00:00-07:00" itemprop="datePublished">Jun 16, 2018
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <h2 id="the-devils-in-the-details-unsupported-scalar-data-types">The Devil’s in the Details: Unsupported scalar data types</h2>

<p>In the <a href="/json/export/import/oracle/2018/06/15/JSON_EXPORT.html">previous</a> post, the first attempt to run EXPORT_SCHEMA on the SH schema failed due to fact one of the tables contained a BLOB column. Fortunately, in that case of the SH schema, the BLOB column was in a table that needed to be excluded from the export operation, and all remaining tables in the SH schema use data types that are directly supported by the JSON_ARRAY operator However that incident was simply a precursor for the problems that are encountered when attempting to process the OE schema.</p>

<pre><code class="language-SQL">SQL&gt; select JSON_EXPORT.EXPORT_SCHEMA('OE') from dual;
</code></pre>

<pre><code class="language-SQL">ERROR:
ORA-40654: Input to JSON generation function has unsupported data type.
ORA-06512: at "SYSTEM.JSON_EXPORT", line 197
</code></pre>

<p>In order to determine the set of data types supported by JSON_ARRAY in each database release  a simple script was developed. The script creates a table containing one column for each possible scalar data type, insert 1 row of data into the tables and then attempts to perform a JSON_ARRAY operation on each column. The script, DATA_TYPE_TEST.sql can be found on GitHub in the project’s test directory. The results of running this script on 12.2 and 18.1 are documented in the following table.</p>

<table>
  <thead>
    <tr>
      <th>Data Type</th>
      <th>12cR2</th>
      <th>18S</th>
      <th>SQL Workaround</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>CHAR (BYTE semantics)``</td>
      <td>✔️</td>
      <td>✔️</td>
      <td> </td>
    </tr>
    <tr>
      <td>CHAR (CHAR semantics</td>
      <td>:heavy_check_mark:</td>
      <td>✔️</td>
      <td> </td>
    </tr>
    <tr>
      <td>VARCHAR2 (Byte Semantics)</td>
      <td>✔️</td>
      <td>✔️</td>
      <td> </td>
    </tr>
    <tr>
      <td>VARCHAR2 (Char Semantics)</td>
      <td>✔️</td>
      <td>✔️</td>
      <td> </td>
    </tr>
    <tr>
      <td>NCHAR</td>
      <td>❗️</td>
      <td>✔️</td>
      <td> </td>
    </tr>
    <tr>
      <td>NVARCHAR</td>
      <td>❗️</td>
      <td>✔️</td>
      <td> </td>
    </tr>
    <tr>
      <td>NUMBER</td>
      <td>✔️</td>
      <td>✔️</td>
      <td> </td>
    </tr>
    <tr>
      <td>NUMBER (Precision)</td>
      <td>✔️</td>
      <td>✔️</td>
      <td> </td>
    </tr>
    <tr>
      <td>NUMBER (Precision,Scale)</td>
      <td>✔️</td>
      <td>✔️</td>
      <td> </td>
    </tr>
    <tr>
      <td>BINARY FLOAT</td>
      <td>❌</td>
      <td>✔️</td>
      <td>TO_CHAR</td>
    </tr>
    <tr>
      <td>BINARY DECIMAL</td>
      <td>❌</td>
      <td>✔️</td>
      <td>TO_CHAR</td>
    </tr>
    <tr>
      <td>DATE</td>
      <td>✔️</td>
      <td>✔️</td>
      <td> </td>
    </tr>
    <tr>
      <td>TIMESTAMP</td>
      <td>✔️</td>
      <td>✔️</td>
      <td> </td>
    </tr>
    <tr>
      <td>TIMESTAMP WITH TIME ZONE</td>
      <td>✔️</td>
      <td>✔️</td>
      <td> </td>
    </tr>
    <tr>
      <td>TIMESTAMP WITH LOCAL TIME ZONE</td>
      <td>❌</td>
      <td>✔️</td>
      <td>SYS_EXTRACT_UTC</td>
    </tr>
    <tr>
      <td>INTERVAL YEAR TO MONTH</td>
      <td>❌</td>
      <td>✔️</td>
      <td>Custom SQL</td>
    </tr>
    <tr>
      <td>INTERVAL DAY TO SECOND</td>
      <td>❌</td>
      <td>✔️</td>
      <td>Custom SQL</td>
    </tr>
    <tr>
      <td>RAW</td>
      <td>✔️</td>
      <td>✔️</td>
      <td> </td>
    </tr>
    <tr>
      <td>ROWID</td>
      <td>❌</td>
      <td>❌</td>
      <td>ROWIDTOCHAR</td>
    </tr>
    <tr>
      <td>UROWID</td>
      <td>❌</td>
      <td>❌</td>
      <td>ROWIDTOCHAR</td>
    </tr>
    <tr>
      <td>BLOB</td>
      <td>❗️</td>
      <td>✔️</td>
      <td> </td>
    </tr>
    <tr>
      <td>CLOB</td>
      <td>✔️</td>
      <td>✔️</td>
      <td> </td>
    </tr>
    <tr>
      <td>NCLOB</td>
      <td>❗️</td>
      <td>✔️</td>
      <td> </td>
    </tr>
    <tr>
      <td>BFILE</td>
      <td>❌</td>
      <td>❌</td>
      <td> </td>
    </tr>
    <tr>
      <td>XMLTYPE</td>
      <td>❌</td>
      <td>❌</td>
      <td>XMLSEQUENCE</td>
    </tr>
    <tr>
      <td>LONG</td>
      <td>❌</td>
      <td>❌</td>
      <td> </td>
    </tr>
    <tr>
      <td>LONG RAW</td>
      <td>❌</td>
      <td>❌</td>
      <td> </td>
    </tr>
  </tbody>
</table>

<p>The script also demonstrates potential solutions for some of the data types that are not supported natively.</p>

<p>❗️ The JSON_ARRAY documentation for Oracle 12.2 clearly states that BLOB is not a supported data type. However, as is shown by the DATA_TYPE_TESTS.sql script, if a BLOB is passed to the JSON_ARRAY operator it does not raise the expected “ORA-40654: Input to JSON generation function has unsupported data type” exception. Rather it mistakenly assumes that the BLOB column  contains textual data and attempts to process the content as text. If the BLOB contains binary data this will typically result in the exception “ORA-40474: invalid UTF-8 byte sequence in JSON data” being raised by JSON_ARRAY. In Oracle 18c the BLOB data type is supported by JSON_ARRAY. When a  BLOB is passed to JSON_ARRAY a HEXBINARY encoded representation of the BLOB’s content is returned by the JSON_ARRAY operator.</p>

<p>❗️There is a similar issue with the way in which JSON_ARRAY handles of NCHAR, NVARCHAR2 and NCLOB in database 12.2 which can also result in exception  “ORA-40474: invalid UTF-8 byte sequence in JSON data”  being raised. A possible workaround for this, at least in databases configured to use ‘AL32UTF8’ as the database character set, is to apply the TO_CHAR or TO_CLOB operator to the column before passing it to the JSON_ARRAY operator. Note that it is likely that this workaround will fail in non AL32UTF8 environments.</p>

<p>Running the DATA_TYPE_TESTS.sql script in Oracle 18 conforms native support for Interval data types, and the value of an Interval column is output in a format compliant with the ISO 8601 standard. In order to support Interval data types in Oracle12.2 it is necessary to use the SQL extract function to decompose the interval value into discrete components and then construct a string that mimics the native support provided by Oracle 18.</p>

<p>Implementing the workarounds requires modifying the column list generated by GENERATE_STATEMENT to incorporate the appropriate workarounds. A case statement, based on the DATA_TYPE column,  is used to apply each workaround when generating the list of columns names. Conditional compilation is used to determine which workarounds are required in which database version. The result of implementing this logic is the query is now generates the “select list” required to export the table’s content as JSON, rather than a list of the columns in the table.</p>

<p>The case statement required to generate the select list is shown below</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">case</span>
   <span class="c1">-- For some reason RAW columns have DATA_TYPE_OWNER set to the current schema and </span>
   <span class="c1">-- the condition DATA_TYPE_OWNER is not NULL is requried to identify OBJECT types</span>
   <span class="k">when</span> <span class="n">DATA_TYPE</span> <span class="o">=</span> <span class="s1">'RAW'</span>
     <span class="k">then</span> <span class="s1">'"'</span> <span class="o">||</span> <span class="k">COLUMN_NAME</span> <span class="o">||</span> <span class="s1">'"'</span>
  <span class="err">$</span><span class="n">IF</span> <span class="k">NOT</span> <span class="n">JSON_FEATURE_DETECTION</span><span class="p">.</span><span class="n">CLOB_SUPPORTED</span> <span class="err">$</span><span class="k">THEN</span>
  <span class="cm">/*
  ** Pre 18.1 Some Scalar Data Types are not natively supported by JSON_ARRAY()
  */</span>
  <span class="k">when</span> <span class="n">DATA_TYPE</span> <span class="k">in</span> <span class="p">(</span><span class="s1">'BINARY_DOUBLE'</span><span class="p">,</span><span class="s1">'BINARY_FLOAT'</span><span class="p">)</span>
    <span class="k">then</span> <span class="s1">'TO_CHAR("'</span> <span class="o">||</span> <span class="k">COLUMN_NAME</span> <span class="o">||</span> <span class="s1">'")'</span>
  <span class="k">when</span> <span class="n">DATA_TYPE</span> <span class="k">LIKE</span> <span class="s1">'TIMESTAMP%WITH LOCAL TIME ZONE'</span>
    <span class="k">then</span> <span class="s1">'TO_CHAR(SYS_EXTRACT_UTC("'</span> <span class="o">||</span> <span class="k">COLUMN_NAME</span> <span class="o">||</span> <span class="s1">'"),</span><span class="se">''</span><span class="s1">IYYY-MM-DD"T"HH24:MI:SS.FF9"Z"</span><span class="se">''</span><span class="s1">)'</span>
  <span class="k">when</span> <span class="n">DATA_TYPE</span> <span class="k">LIKE</span> <span class="s1">'INTERVAL DAY% TO SECOND%'</span>
    <span class="k">then</span> <span class="s1">'</span><span class="se">''</span><span class="s1">P</span><span class="se">''</span><span class="s1"> || extract(DAY FROM "'</span> <span class="o">||</span> <span class="k">COLUMN_NAME</span> <span class="o">||</span> <span class="s1">'") || </span><span class="se">''</span><span class="s1">D</span><span class="se">''</span><span class="s1"> ||
          </span><span class="se">''</span><span class="s1">T</span><span class="se">''</span><span class="s1"> || case 
                     when extract(HOUR FROM  "'</span> <span class="o">||</span> <span class="k">COLUMN_NAME</span> <span class="o">||</span> <span class="s1">'") &lt;&gt; 0 
                       then extract(HOUR FROM  "'</span> <span class="o">||</span> <span class="k">COLUMN_NAME</span> <span class="o">||</span> <span class="s1">'") || </span><span class="se">''</span><span class="s1">H</span><span class="se">''</span><span class="s1"> 
                   end 
                || case 
                     when extract(MINUTE FROM  "'</span> <span class="o">||</span> <span class="k">COLUMN_NAME</span> <span class="o">||</span> <span class="s1">'") &lt;&gt; 0 
                     then extract(MINUTE FROM  "'</span> <span class="o">||</span> <span class="k">COLUMN_NAME</span> <span class="o">||</span> <span class="s1">'") || </span><span class="se">''</span><span class="s1">M</span><span class="se">''</span><span class="s1"> 
                   end
	            || case 
                     when extract(SECOND FROM  "'</span> <span class="o">||</span> <span class="k">COLUMN_NAME</span> <span class="o">||</span> <span class="s1">'") &lt;&gt; 0 
                     then extract(SECOND FROM  "'</span> <span class="o">||</span> <span class="k">COLUMN_NAME</span> <span class="o">||</span> <span class="s1">'") ||  </span><span class="se">''</span><span class="s1">S</span><span class="se">''</span><span class="s1">
                   end'</span>
  <span class="k">when</span> <span class="n">DATA_TYPE</span> <span class="k">LIKE</span> <span class="s1">'INTERVAL YEAR% TO MONTH%'</span>
    <span class="k">then</span> <span class="s1">'</span><span class="se">''</span><span class="s1">P</span><span class="se">''</span><span class="s1"> || extract(YEAR FROM "'</span> <span class="o">||</span> <span class="k">COLUMN_NAME</span> <span class="o">||</span> <span class="s1">'") || 
          </span><span class="se">''</span><span class="s1">Y</span><span class="se">''</span><span class="s1"> || case 
                     when extract(MONTH FROM  "'</span> <span class="o">||</span> <span class="k">COLUMN_NAME</span> <span class="o">||</span> <span class="s1">'") &lt;&gt; 0 
                       then extract(MONTH FROM  "'</span> <span class="o">||</span> <span class="k">COLUMN_NAME</span> <span class="o">||</span> <span class="s1">'") || </span><span class="se">''</span><span class="s1">M</span><span class="se">''</span><span class="s1">
                   end'</span>
  <span class="k">when</span> <span class="n">DATA_TYPE</span> <span class="k">in</span> <span class="p">(</span><span class="s1">'NCHAR'</span><span class="p">,</span><span class="s1">'NVARCHAR2'</span><span class="p">)</span>
    <span class="k">then</span> <span class="s1">'TO_CHAR("'</span> <span class="o">||</span> <span class="k">COLUMN_NAME</span> <span class="o">||</span> <span class="s1">'")'</span>
  <span class="k">when</span> <span class="n">DATA_TYPE</span> <span class="o">=</span> <span class="s1">'NCLOB'</span>
    <span class="k">then</span> <span class="s1">'TO_CLOB("'</span> <span class="o">||</span> <span class="k">COLUMN_NAME</span> <span class="o">||</span> <span class="s1">'")'</span>
  <span class="err">$</span><span class="k">END</span>
  <span class="cm">/*
  ** Quick Fixes for datatypes not natively supported
  */</span>
  <span class="k">when</span> <span class="n">DATA_TYPE</span> <span class="o">=</span> <span class="s1">'XMLTYPE'</span>  <span class="c1">-- Can be owned by SYS or PUBLIC</span>
    <span class="k">then</span> <span class="s1">'case 
            when "'</span> <span class="o">||</span>  <span class="k">COLUMN_NAME</span> <span class="o">||</span> <span class="s1">'" is NULL 
              then NULL 
              else XMLSERIALIZE(CONTENT "'</span> <span class="o">||</span>  <span class="k">COLUMN_NAME</span> <span class="o">||</span> <span class="s1">'" as CLOB) 
            end'</span>
  <span class="k">when</span> <span class="n">DATA_TYPE</span> <span class="o">=</span> <span class="s1">'ROWID'</span> <span class="k">or</span> <span class="n">DATA_TYPE</span> <span class="o">=</span> <span class="s1">'UROWID'</span>
     <span class="k">then</span> <span class="s1">'ROWIDTOCHAR("'</span> <span class="o">||</span> <span class="k">COLUMN_NAME</span> <span class="o">||</span> <span class="s1">'")'</span>
  <span class="cm">/*
  ** Comment outunsupported scalar data types and Object types
  */</span>
  <span class="k">when</span> <span class="n">DATA_TYPE</span> <span class="k">in</span> <span class="p">(</span><span class="s1">'LONG'</span><span class="p">,</span><span class="s1">'LONG RAW'</span><span class="p">,</span><span class="s1">'BFILE'</span><span class="p">,</span><span class="s1">'BLOB'</span><span class="p">)</span>
    <span class="k">then</span> <span class="s1">'</span><span class="se">''</span><span class="s1">"'</span> <span class="o">||</span> <span class="k">COLUMN_NAME</span> <span class="o">||</span> <span class="s1">'". Unsupported data type ["'</span> <span class="o">||</span> <span class="n">DATA_TYPE</span> <span class="o">||</span> <span class="s1">'"]</span><span class="se">''</span><span class="s1">'</span>
  <span class="k">when</span> <span class="n">DATA_TYPE_OWNER</span> <span class="k">is</span> <span class="k">not</span> <span class="k">NULL</span>
    <span class="k">then</span> <span class="s1">'</span><span class="se">''</span><span class="s1">"'</span> <span class="o">||</span> <span class="k">COLUMN_NAME</span>  <span class="o">||</span> <span class="s1">'". Unsupported object type ["'</span> 
               <span class="o">||</span> <span class="n">DATA_TYPE_OWNER</span> <span class="o">||</span> <span class="s1">'"."'</span> <span class="o">||</span> <span class="n">DATA_TYPE</span> <span class="o">||</span> <span class="s1">'"]</span><span class="se">''</span><span class="s1">'</span>
  <span class="k">else</span>
    <span class="s1">'"'</span> <span class="o">||</span> <span class="k">COLUMN_NAME</span> <span class="o">||</span> <span class="s1">'"'</span>

</code></pre></div></div>

<p>The above implementation assumes that applying the patch to enable CLOB support to Database 12.2 will also extend the list of data types supported natively by JSON_ARRAY in 12.2. If this is not the case further ‘DUCK TYPING’ may be necessary to determine which data types are supported natively in which database release in order to generate a correctly optimized column list.</p>

<p>After implementing these changes  an EXPORT_SCHEMA operation on the OE schema succeeds. However a closer examination of the JSON document generated shows that the export failed to export all of the data in the schema The following table shows the results of the export operation</p>

<table>
  <thead>
    <tr>
      <th>Table Name</th>
      <th>Results</th>
      <th>Cause</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>INVENTORIES</td>
      <td>✔️</td>
      <td> </td>
    </tr>
    <tr>
      <td>ORDERS</td>
      <td>✔️</td>
      <td> </td>
    </tr>
    <tr>
      <td>ORDER_ITEMS</td>
      <td>✔️</td>
      <td> </td>
    </tr>
    <tr>
      <td>PROMOTIONS</td>
      <td>✔️</td>
      <td> </td>
    </tr>
    <tr>
      <td>PROCUCT_INFORMATION</td>
      <td>✔️</td>
      <td> </td>
    </tr>
    <tr>
      <td>CUSTOMERS</td>
      <td>❌</td>
      <td>Unsupported OBJECT Type Column</td>
    </tr>
    <tr>
      <td>WAREHOUSES</td>
      <td>❌</td>
      <td>Unsupported OBJECT Type Column</td>
    </tr>
    <tr>
      <td>CATEOGORIES</td>
      <td>❌</td>
      <td>Skipped OBJECT Table</td>
    </tr>
    <tr>
      <td>PURCHASEORDER</td>
      <td>❌</td>
      <td>Skipped OBJECT (XMLTYPE) Table</td>
    </tr>
  </tbody>
</table>

<p>At this point EXPORT_SCHEMA is capable of handling most of the common scalar data types supported by the Oracle Database. The <a href="/json/export/import/oracle/2018/06/17/BFILE-and-BLOB.html">next</a> post will explain how in-line PL/SQL procedures can be used to enable support for BIFLE and BLOB data types.</p>

  </div><a class="u-url" href="/json/export/import/oracle/2018/06/16/Unsupported-Scalar-Types.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">JSON Exchange</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">JSON Exchange</li><li><a class="u-email" href="mailto:mdd@appdev4db.com">mdd@appdev4db.com</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/markddrake"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">markddrake</span></a></li><li><a href="https://www.twitter.com/markddrake"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">markddrake</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>A simple utility for exporting and importing data using JSON</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
